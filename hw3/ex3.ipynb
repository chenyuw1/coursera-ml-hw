{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import scipy to read .mat file\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# fmin_cg\n",
    "from scipy.optimize import fmin_cg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = '/Users/Chenyu/Documents/Coursera/Machine Learning/hw3/machine-learning-ex3/ex3/ex3data1.mat'\n",
    "mat = loadmat(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 401)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x = pd.DataFrame(mat['X'])\n",
    "data_y = pd.DataFrame(mat['y'])\n",
    "data = pd.concat([data_x, data_y], axis = 1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dispData(data, row, col):\n",
    "    mat = np.array(data).reshape((row, col)).T\n",
    "    imgplt = plt.imshow(mat, cmap='gray')\n",
    "    return imgplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1111330f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAD8CAYAAACLgjpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b69b668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dispData(data_x.iloc[1980, :], 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "sigmd = np.vectorize(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorized cost function\n",
    "def costFunc_reg(theta, x, y, l):\n",
    "    m = len(y)\n",
    "    theta = np.array(theta)\n",
    "    y = np.array(y)\n",
    "    hx = sigmd(x.dot(theta.T))\n",
    "    \n",
    "    if (hx.all() != 0) and ((1 - hx).all() != 0):\n",
    "        \n",
    "        j = (- y.T * np.log(hx) - (1. - y.T) * np.log(1 - hx)).sum() / m + l * (theta ** 2).sum() / 2. / m\n",
    "    \n",
    "    \n",
    "    else: j = 100000\n",
    "    \n",
    "    #j = np.array(j)\n",
    "    \n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 555. ,    3. ,    4.5,    6. ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([1, 2, 3, 4])\n",
    "test2 = (test / 2.).flatten()\n",
    "test3 = test2 + test\n",
    "test3[0] = 555\n",
    "test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([1, 2, 3, 4])\n",
    "test_2 = test ** 2\n",
    "test_2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "## It's important to keep the grad and theta as the 1d array\n",
    "## when doing the calculations\n",
    "#############################################################\n",
    "\n",
    "\n",
    "def grad_reg(theta, x, y, l):\n",
    "    m = len(y)\n",
    "    theta = np.array(theta)\n",
    "    y = np.array(y)\n",
    "    hx = sigmd(np.dot(x, theta.T))\n",
    "    \n",
    "    loss = hx - y.T\n",
    "    #print (\"loss shape: \", np.shape(loss))\n",
    "    grad = (np.dot(loss, x) / m).flatten()\n",
    "    #print (\"grad shape: \", np.shape(grad))\n",
    "    #print (\"theta shape: \", np.shape(theta))\n",
    "    reg = [elem * l * 1. / m for elem in theta]\n",
    "    #print (\"reg shape: \", np.shape(reg))\n",
    "    grad += reg\n",
    "    \n",
    "    #grad = np.dot(hx - y.T, x) / m + theta * l / m\n",
    "    #print (\"grad shape: \", np.shape(grad))\n",
    "\n",
    "    grad[0] = ((hx[0] - y[0]) * x.iloc[0, :]).sum() / m\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test scipy.optimize.fmin_cg\n",
    "l = 1\n",
    "x0 = [1] * data_x.shape[0]\n",
    "df0 = pd.DataFrame(x0)\n",
    "testx = pd.concat([df0, data_x], axis = 1)\n",
    "#testx\n",
    "testy = (data_y == 1).astype(int)\n",
    "theta0 = [0] * testx.shape[1]\n",
    "myarg = (testx, testy, l)\n",
    "\n",
    "\n",
    "#cf = costFunc_reg(theta0, testx, testy, l)\n",
    "#cf\n",
    "#grad = grad_reg(theta0, testx, testy, l)\n",
    "#np.shape(grad)\n",
    "\n",
    "#theta_test = fmin_cg(costFunc_reg, theta0, args = myarg, fprime = grad_reg)\n",
    "#theta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.027971\n",
      "         Iterations: 59\n",
      "         Function evaluations: 209\n",
      "         Gradient evaluations: 209\n"
     ]
    }
   ],
   "source": [
    "#theta_test = fmin_cg(costFunc_reg, theta0, args = myarg, fprime = grad_reg, disp = 1, retall = 1)\n",
    "theta_test = fmin_cg(costFunc_reg, theta0, args = myarg, fprime = grad_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(theta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-vs-all classification\n",
    "def oneVsAll(x, y, num_labels, l):\n",
    "    \n",
    "    # add x0=1 to x\n",
    "    x0 = [1] * x.shape[0]\n",
    "    df0 = pd.DataFrame(x0)\n",
    "    x = pd.concat([df0, x], axis = 1)\n",
    "    \n",
    "    # apply one-vs-all algorithm\n",
    "    m, n = x.shape\n",
    "    theta0 = np.zeros(n)\n",
    "    theta = np.zeros(shape = (num_labels, n))\n",
    "    for k in range(num_labels):\n",
    "        if k == 0:\n",
    "            label = (y == 10).astype(int)\n",
    "        else:\n",
    "            label = (y == k).astype(int)\n",
    "        train = fmin_cg(costFunc_reg, theta0, args = (x, label, l), fprime = grad_reg)\n",
    "        theta[k] = train\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.029663\n",
      "         Iterations: 46\n",
      "         Function evaluations: 302\n",
      "         Gradient evaluations: 290\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.030879\n",
      "         Iterations: 55\n",
      "         Function evaluations: 185\n",
      "         Gradient evaluations: 185\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.076552\n",
      "         Iterations: 144\n",
      "         Function evaluations: 447\n",
      "         Gradient evaluations: 436\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.086334\n",
      "         Iterations: 83\n",
      "         Function evaluations: 230\n",
      "         Gradient evaluations: 230\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.057866\n",
      "         Iterations: 70\n",
      "         Function evaluations: 213\n",
      "         Gradient evaluations: 213\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.082335\n",
      "         Iterations: 80\n",
      "         Function evaluations: 332\n",
      "         Gradient evaluations: 321\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.041239\n",
      "         Iterations: 60\n",
      "         Function evaluations: 197\n",
      "         Gradient evaluations: 197\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.051386\n",
      "         Iterations: 73\n",
      "         Function evaluations: 225\n",
      "         Gradient evaluations: 225\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.513243\n",
      "         Iterations: 1\n",
      "         Function evaluations: 14\n",
      "         Gradient evaluations: 2\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.105675\n",
      "         Iterations: 134\n",
      "         Function evaluations: 383\n",
      "         Gradient evaluations: 371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 401)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_opt = oneVsAll(data_x, data_y, 10, 1.5)\n",
    "theta_opt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.23050503e-01,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "         -1.68445519e-04,   8.15224267e-06,   0.00000000e+00],\n",
       "       [ -8.37321385e-03,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          1.26937744e-03,   7.25984536e-09,   0.00000000e+00],\n",
       "       [ -2.83097942e-01,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          3.35400903e-03,  -3.83779462e-04,   0.00000000e+00],\n",
       "       ..., \n",
       "       [ -3.95275388e-02,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "         -6.95433345e-04,   8.32631102e-05,   0.00000000e+00],\n",
       "       [ -3.92171739e-03,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "         -1.23820650e-06,   1.27805514e-07,   0.00000000e+00],\n",
       "       [ -5.77760228e-01,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "         -4.08352655e-03,   3.26859522e-04,   0.00000000e+00]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predOneVsAll(x, theta):\n",
    "    x0 = [1] * x.shape[0]\n",
    "    df0 = pd.DataFrame(x0)\n",
    "    x = pd.concat([df0, x], axis = 1)\n",
    "    \n",
    "    hx = sigmd(x.dot(theta.T))\n",
    "    \n",
    "    pred = np.argmax(hx, axis = 1)\n",
    "    \n",
    "    pred[pred == 0] = 10\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = predOneVsAll(data_x, theta_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0  10\n",
       "1  10\n",
       "2  10\n",
       "3  10\n",
       "4  10"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = pd.DataFrame(pred_test)\n",
    "pred_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y, pred):\n",
    "    m = len(y)\n",
    "    count = (y == pred).sum()\n",
    "    accuracy = count / m\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.8642\n",
       "dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu = accuracy(data_y, pred_test)\n",
    "accu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

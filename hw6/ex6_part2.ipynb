{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc1 = r'C:\\Users\\c0w00f8.WMSC\\Documents\\Coursera\\1. Machine Learning\\machine-learning-ex6\\ex6\\spamTest.mat'\n",
    "spamTest = loadmat(loc1)\n",
    "spamTest_x = spamTest['Xtest']\n",
    "spamTest_y = spamTest['ytest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc2 = r'C:\\Users\\c0w00f8.WMSC\\Documents\\Coursera\\1. Machine Learning\\machine-learning-ex6\\ex6\\spamTrain.mat'\n",
    "spamTrain = loadmat(loc2)\n",
    "#spamTrain\n",
    "spamTrain_x = spamTrain['X']\n",
    "spamTrain_y = spamTrain['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to read txt files\n",
    "def readFile(filename):\n",
    "    with open(filename, 'r') as myfile:\n",
    "        content = myfile.read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"> Anyone knows how much it costs to host a web portal ?\\n>\\nWell, it depends on how many visitors you're expecting.\\nThis can be anywhere from less than 10 bucks a month to a couple of $100. \\nYou should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \\nif youre running something big..\\n\\nTo unsubscribe yourself from this mailing list, send an email to:\\ngroupname-unsubscribe@egroups.com\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRead = readFile('emailSample1.txt')\n",
    "testRead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocabulary list as a matrix\n",
    "def getVocabList1(filename):\n",
    "    with open(filename, 'r') as myfile:\n",
    "        lines = myfile.readlines()\n",
    "    lines = [x.strip('\\n') for x in lines]\n",
    "    vlist = [x.split('\\t') for x in lines]\n",
    "    \n",
    "    vlist = np.array(vlist)\n",
    "    \n",
    "    return vlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1895', 'your'], dtype='<U40')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testV = getVocabList1('vocab.txt')\n",
    "testV[1894]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocab list as a dictionary\n",
    "def getVocabList(filename):\n",
    "    vlist = dict()\n",
    "    with open(filename, 'r') as myfile:\n",
    "        lines = myfile.readlines()\n",
    "    lines = [x.strip('\\n') for x in lines]\n",
    "    lines = [x.split('\\t') for x in lines]\n",
    "    \n",
    "    for item in lines:\n",
    "        vlist[item[1]] = int(item[0])\n",
    "    \n",
    "    return vlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1899"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testV2 = getVocabList('vocab.txt')\n",
    "ww = 'anyon'\n",
    "#ww in testV2\n",
    "#testV2[ww]\n",
    "#len(testV2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform txt content to words indices\n",
    "def processEmail(email):\n",
    "    \n",
    "    # import vocabList\n",
    "    vlist = getVocabList('vocab.txt')\n",
    "    \n",
    "    # lower-casing\n",
    "    email = email.lower()\n",
    "    \n",
    "    # stripping html\n",
    "    email = re.sub('<[^<>]+>', '', email)\n",
    "    \n",
    "    # normalizing numbers\n",
    "    email = re.sub('[0-9]+', 'number', email)\n",
    "    \n",
    "    # normalizing urls\n",
    "    # Look for strings starting with http:// or https://\n",
    "    email = re.sub('(http|https)://[^\\s]*', 'httpaddr', email)\n",
    "    \n",
    "    # normalizing email address\n",
    "    # Look for strings with @ in the middle\n",
    "    email = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', email)\n",
    "    \n",
    "    # normalizing dollars\n",
    "    email = re.sub('[$]+', 'dollar', email)\n",
    "    \n",
    "    splitter = re.compile('[\\s@$/#.-:&*+=\\[\\]?!(){},''\">_<;%\\']+')\n",
    "    word_indices = []\n",
    "    \n",
    "    for word in splitter.split(email):\n",
    "        #print (word)\n",
    "        word = re.sub('\\W', '', word)\n",
    "        ps = nltk.stem.PorterStemmer()\n",
    "        word_stemmed = ps.stem(word)\n",
    "        #print (word, word_stemmed)\n",
    "        \n",
    "        if word_stemmed in vlist:\n",
    "            word_indices.append(vlist[word_stemmed])\n",
    "\n",
    "    \n",
    "    return word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testP = processEmail(testRead)\n",
    "len(testP)\n",
    "#testP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shop'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "www = 'shopping'\n",
    "ps = nltk.stem.PorterStemmer()\n",
    "ps.stem(www)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform word indices to features\n",
    "def emailFeatures(word_ind):\n",
    "    # import vocabList\n",
    "    vlist = getVocabList('vocab.txt')\n",
    "    \n",
    "    # number of features\n",
    "    n = len(vlist)\n",
    "    \n",
    "    x = np.zeros(n)\n",
    "    \n",
    "    for i in word_ind:\n",
    "        x[i-1] = 1\n",
    "    \n",
    "    x = x.T.reshape((1, n))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFeature = emailFeatures(testP)\n",
    "(testFeature==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training func form part 1\n",
    "def svmTrain(x, y, c, kernal, sig=0.01):\n",
    "    y = y.flatten()\n",
    "    if kernel == 'linear':\n",
    "        clf = svm.SVC(kernel=kernel, C=c)\n",
    "        \n",
    "    if kernel == 'gaussian':\n",
    "        clf = svm.SVC(kernel='rbf', C=c, gamma=1/sigma**2/2)\n",
    "    \n",
    "    clf.fit(x, y)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "c = 0.1\n",
    "kernel = 'linear'\n",
    "\n",
    "model = svmTrain(spamTrain_x, spamTrain_y, c, kernel)\n",
    "\n",
    "pred = model.predict(spamTrain_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99825"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu_train = (pred == spamTrain_y.flatten()).sum() / spamTrain_y.shape[0]\n",
    "accu_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predTest = model.predict(spamTest_x)\n",
    "accu_test = (predTest == spamTest_y.flatten()).sum() / spamTest_y.shape[0]\n",
    "accu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['our',\n",
       " 'click',\n",
       " 'remov',\n",
       " 'guarante',\n",
       " 'visit',\n",
       " 'basenumb',\n",
       " 'dollar',\n",
       " 'will',\n",
       " 'price',\n",
       " 'pleas',\n",
       " 'most',\n",
       " 'nbsp',\n",
       " 'lo',\n",
       " 'ga',\n",
       " 'hour']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the most predictive words\n",
    "w = model.coef_\n",
    "ind = w.flatten().argsort()[::-1][:15]\n",
    "\n",
    "vlist = getVocabList1('vocab.txt')\n",
    "topWords = []\n",
    "\n",
    "for i in ind:\n",
    "    topWords.append(vlist[i, 1])\n",
    "\n",
    "topWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the email\n",
    "def testMain(filename, model):\n",
    "    content = readFile(filename)\n",
    "    word_indices = processEmail(content)\n",
    "    x = emailFeatures(word_indices)\n",
    "    pred = model.predict(x)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0.1\n",
    "kernel = 'linear'\n",
    "modelTest = svmTrain(spamTrain_x, spamTrain_y, c, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=uint8)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'spamSample2.txt'\n",
    "p = testMain(filename, modelTest)\n",
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

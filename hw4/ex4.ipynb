{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import fmin_cg\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = r'C:\\Users\\c0w00f8.WMSC\\Documents\\Coursera\\1. Machine Learning\\machine-learning-ex4\\ex4\\ex4data1.mat'\n",
    "mat_data = loadmat(loc)\n",
    "data_x = mat_data['X']\n",
    "data_y = mat_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the label 10 back to 0\n",
    "#data_y[data_y == 10] = 0\n",
    "\n",
    "# here for this assignment, don't change 10 to 0!!! since the weights provided was based on label 10!!! \n",
    "# if change to 0, the cost test result would be around 10.44\n",
    "# if stay 10, it would be 0.287629, the correct reference provided by the writeup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load provided weights\n",
    "loc = r'C:\\Users\\c0w00f8.WMSC\\Documents\\Coursera\\1. Machine Learning\\machine-learning-ex4\\ex4\\ex4weights.mat'\n",
    "mat = loadmat(loc)\n",
    "theta1 = mat['Theta1']\n",
    "theta2 = mat['Theta2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 401)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_x.shape\n",
    "#theta1.shape - 25 * 401\n",
    "#theta2.shape - 10 * 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10285,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_f = theta1.flatten()\n",
    "t2_f = theta2.flatten()\n",
    "t = np.append(t1_f, t2_f)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mReform(x, k):\n",
    "    m = x.shape[0]\n",
    "    mat = np.zeros((m, 1))\n",
    "    for i in range(k):\n",
    "        label = (x == i+1).astype(int)\n",
    "        mat = np.hstack((mat, label))\n",
    "    return mat[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy = mReform(data_y, 10)\n",
    "testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1, 2],\n",
       "       [9, 1, 5],\n",
       "       [7, 4, 6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.arange(9).reshape(3, 3)\n",
    "b1 = np.array([\n",
    "    [3, 1, 2],\n",
    "    [9, 1, 5],\n",
    "    [7, 4, 6]\n",
    "])\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  1,  4],\n",
       "       [81,  1, 25],\n",
       "       [49, 16, 36]], dtype=int32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3,  -2,  -4],\n",
       "       [-12,  -5, -10],\n",
       "       [-13, -11, -14]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (- a1 - b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  4],\n",
       "       [27,  4, 25],\n",
       "       [42, 28, 48]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(a1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(a1, b1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.09861229, 0.        , 0.69314718],\n",
       "       [2.19722458, 0.        , 1.60943791],\n",
       "       [1.94591015, 1.38629436, 1.79175947]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  1.38629436],\n",
       "       [ 6.59167373,  0.        ,  8.04718956],\n",
       "       [11.67546089,  9.70406053, 14.33407575]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(np.log(b1), a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnCost(theta, hid_size, x, y, num_labels, lam):\n",
    "    # assume the network only have 1 input layer, 1 hidden layer, and 1 output layer\n",
    "    \n",
    "    m = x.shape[0]\n",
    "    \n",
    "    # reshape theta1 and theta2\n",
    "    inp_size = x.shape[1]\n",
    "    theta_cutoff = hid_size * (inp_size + 1)\n",
    "    theta1 = theta[:theta_cutoff].reshape((hid_size, inp_size + 1))\n",
    "    theta2 = theta[theta_cutoff:].reshape((num_labels, hid_size + 1))\n",
    "    #print ('theta1', type(theta1), theta1.shape)\n",
    "    #print ('theta2', type(theta2), theta2.shape)\n",
    "\n",
    "    \n",
    "    # adjust x and insert x0 = 1\n",
    "    x = np.insert(x, 0, 1, axis = 1)\n",
    "    # x.shape - 5000 * 401\n",
    "    \n",
    "    # compute hidden layer value\n",
    "    hidden = sigmoid(x.dot(theta1.T))\n",
    "    #print ('hidden layer', type(hidden), hidden.shape)\n",
    "    # hidden.shape - 5000 * 25\n",
    "    \n",
    "    # add bias unit to hidden layer\n",
    "    hid = np.insert(hidden, 0, 1, axis = 1)\n",
    "    #print ('hid+bias unit', type(hid), hid.shape)\n",
    "    # hid.shape - 5000 * 26\n",
    "    \n",
    "    pred = sigmoid(hid.dot(theta2.T))\n",
    "    #print ('pred', type(pred), pred.shape)\n",
    "    # pred.shape - 5000 * 10\n",
    "    \n",
    "    #out = np.argmax(pred, axis = 1).reshape((m, 1))\n",
    "    #print ('out', type(out), out.shape)\n",
    "    #out = mReform(out, num_labels)\n",
    "    \n",
    "    # reform y to matrix\n",
    "    y = mReform(y,  num_labels)\n",
    "    # turn y into 5000 * 10 matrix\n",
    "    \n",
    "    # compute cost\n",
    "\n",
    "    \n",
    "    j =  ( - np.multiply(y, np.log(pred)) - np.multiply(1 - y, np.log(1 - pred))).sum() / m\n",
    "    \n",
    "    # perform the same when using for-loop\n",
    "    #cost = 0\n",
    "    #for i in range(pred.shape[0]):\n",
    "    #    for j in range(pred.shape[1]):\n",
    "    #        cost = cost - y[i, j] * np.log(pred[i, j]) - (1 - y[i, j]) * np.log(1 - pred[i, j])\n",
    "    \n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2876291651613189"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test nnCost\n",
    "\n",
    "testC = nnCost(t, 25, data_x, data_y, 10, 1)\n",
    "testC\n",
    "# ~0.287629\n",
    "\n",
    "#tt1, tt2 = nnCost(t, 25, data_x, data_y, 10, 1)\n",
    "#if ((tt1 == theta1).all() == True) and ((tt2 == theta2).all() == True):\n",
    "#    print (\"theta reshape test passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnCostReg(theta, hid_size, x, y, num_labels, lam):    \n",
    "    m = x.shape[0]\n",
    "    \n",
    "    # reshape theta1 and theta2\n",
    "    inp_size = x.shape[1]\n",
    "    theta_cutoff = hid_size * (inp_size + 1)\n",
    "    theta1 = theta[:theta_cutoff].reshape((hid_size, inp_size + 1))\n",
    "    theta2 = theta[theta_cutoff:].reshape((num_labels, hid_size + 1))\n",
    "    #theta1.shape - 25 * 401\n",
    "    #theta2.shape - 10 * 26\n",
    "    \n",
    "    # adjust x and insert x0 = 1\n",
    "    x = np.insert(x, 0, 1, axis = 1)\n",
    "    # x.shape - 5000 * 401\n",
    "    \n",
    "    # compute hidden layer value\n",
    "    hidden = sigmoid(x.dot(theta1.T))\n",
    "    # hidden.shape - 5000 * 25\n",
    "    \n",
    "    # add bias unit to hidden layer\n",
    "    hid = np.insert(hidden, 0, 1, axis = 1)\n",
    "    # hid.shape - 5000 * 26\n",
    "    \n",
    "    pred = sigmoid(hid.dot(theta2.T))\n",
    "    # pred.shape - 5000 * 10\n",
    "    \n",
    "    # reform y to matrix\n",
    "    y = mReform(y,  num_labels)\n",
    "    # turn y into 5000 * 10 matrix\n",
    "    \n",
    "    # compute cost\n",
    "    j =  ( - np.multiply(y, np.log(pred)) - np.multiply(1 - y, np.log(1 - pred))).sum() / m\n",
    "                                          \n",
    "    # Regularition\n",
    "    reg = ((theta1[:, 1:] ** 2).sum() + (theta2[:, 1:] ** 2).sum()) * lam / 2 / m\n",
    "    \n",
    "    return j + reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38376985909092365"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testR = nnCostReg(t, 25, data_x, data_y, 10, 1)\n",
    "testR\n",
    "# ~0.38377"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmdGrad(x):\n",
    "    return np.multiply(sigmoid(x), 1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randInit(l_in, l_out):\n",
    "    epsilon = 0.12\n",
    "    sample = np.random.uniform(-epsilon, epsilon, l_out * (l_in + 1))\n",
    "    return sample.reshape(l_out, l_in + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(theta, hid_size, x, y, num_labels, lam):\n",
    "    m = x.shape[0]\n",
    "    inp_size = x.shape[1]\n",
    "    theta_cutoff = hid_size * (inp_size + 1)\n",
    "    theta1 = theta[:theta_cutoff].reshape((hid_size, inp_size + 1))\n",
    "    theta2 = theta[theta_cutoff:].reshape((num_labels, hid_size + 1))\n",
    "    \n",
    "    x = np.insert(x, 0, 1, axis = 1)\n",
    "    hidden = sigmoid(x.dot(theta1.T))\n",
    "    # a2 = hid\n",
    "    a2 = np.insert(hidden, 0, 1, axis = 1)\n",
    "    # a3 = pred\n",
    "    a3 = sigmoid(a2.dot(theta2.T))\n",
    "    y = mReform(y,  num_labels)\n",
    "    \n",
    "    error3 = a3 - y\n",
    "    #print ('error3', error3.shape)\n",
    "    #error3.shape - 5000 * 10\n",
    "    \n",
    "    # theta1 - 25 * 401\n",
    "    # theta2 - 10 * 26\n",
    "    # add 1 column to z2\n",
    "    z2 = x.dot(theta1.T)\n",
    "    z2 = np.insert(z2, 0, 1, axis = 1)\n",
    "    # z2.shape - 5000 * 26\n",
    "    \n",
    "    gz2 = sigmdGrad(z2)\n",
    "    # gz2.shape - 5000 * 26\n",
    "    \n",
    "    error2 = np.multiply(error3.dot(theta2), gz2)\n",
    "    #print ('error2', error2.shape)\n",
    "    #error2.shape - 5000 * 26\n",
    "    \n",
    "    delta2 = error3.T.dot(a2)\n",
    "    # print ('delta2', delta2.shape)\n",
    "    # delta2.shape - 10 * 26\n",
    "    \n",
    "    # ignore error2[:,0]\n",
    "    delta1 = error2[:, 1:].T.dot(x)\n",
    "    # print ('delta1', delta1.shape)\n",
    "    # delta1.shape - 25 * 401\n",
    "    \n",
    "    delta1 = (delta1 / m).flatten()\n",
    "    delta2 = (delta2 / m).flatten()\n",
    "    \n",
    "    delta = np.append(delta1, delta2)\n",
    "    #print ('delta', delta.shape)\n",
    "    \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta (10285,)\n"
     ]
    }
   ],
   "source": [
    "testB = backprop(t, 25, data_x, data_y, 10, 1)\n",
    "#testB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compGrad(theta, hid_size, x, y, num_labels, lam):\n",
    "    epsilon = 0.0001\n",
    "    grad = np.zeros(theta.shape)\n",
    "    for i in range(len(theta)):\n",
    "        theta_pos = copy.copy(theta)\n",
    "        theta_neg = copy.copy(theta)\n",
    "        theta_pos[i] += epsilon\n",
    "        theta_neg[i] -= epsilon\n",
    "        \n",
    "        grad[i] = (nnCost(theta_pos, hid_size, x, y, num_labels, lam) - nnCost(theta_neg, hid_size, x, y, num_labels, lam)) /2/epsilon\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkGrad(in_size, hid_size, n_labels, m, lam=1):\n",
    "    # prep data\n",
    "    theta1 = randInit(in_size, hid_size)\n",
    "    #print (\"theta1\", theta1.shape)\n",
    "    theta2 = randInit(hid_size, n_labels)\n",
    "    #print (\"theta2\", theta2.shape)\n",
    "    x = randInit(in_size - 1, m)\n",
    "    #print (\"x\", x.shape)\n",
    "    y = (np.random.randint(1, n_labels+1, m)).reshape(m, 1)\n",
    "    \n",
    "    t1 = theta1.flatten()\n",
    "    t2 = theta2.flatten()\n",
    "    t = np.append(t1, t2)\n",
    "    \n",
    "    gradNN = backprop(t, hid_size, x, y, n_labels, lam)\n",
    "    gradC = compGrad(t, hid_size, x, y, n_labels, lam)\n",
    "    \n",
    "    diff = abs(gradNN - gradC)\n",
    "    \n",
    "    return (diff <= 1e-9).all() == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "if checkGrad(3, 5, 3, 5) == True:\n",
    "    print ('Gradient check passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yy = np.random.randint(1, 6, size=10)\n",
    "#yy = yy.reshape(10, 1)\n",
    "\n",
    "#yy = mReform(yy, 5)\n",
    "#yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropReg(theta, hid_size, x, y, num_labels, lam):\n",
    "    m = x.shape[0]\n",
    "    inp_size = x.shape[1]\n",
    "    theta_cutoff = hid_size * (inp_size + 1)\n",
    "    theta1 = theta[:theta_cutoff].reshape((hid_size, inp_size + 1))\n",
    "    theta2 = theta[theta_cutoff:].reshape((num_labels, hid_size + 1))\n",
    "    \n",
    "    x = np.insert(x, 0, 1, axis = 1)\n",
    "    hidden = sigmoid(x.dot(theta1.T))\n",
    "    # a2 = hid\n",
    "    a2 = np.insert(hidden, 0, 1, axis = 1)\n",
    "    # a3 = pred\n",
    "    a3 = sigmoid(a2.dot(theta2.T))\n",
    "    y = mReform(y,  num_labels)\n",
    "    \n",
    "    error3 = a3 - y\n",
    "    #error3.shape - 5000 * 10\n",
    "    \n",
    "    # theta1 - 25 * 401\n",
    "    # theta2 - 10 * 26\n",
    "    # add 1 column to z2\n",
    "    z2 = x.dot(theta1.T)\n",
    "    z2 = np.insert(z2, 0, 1, axis = 1)\n",
    "    # z2.shape - 5000 * 26\n",
    "    \n",
    "    gz2 = sigmdGrad(z2)\n",
    "    # gz2.shape - 5000 * 26\n",
    "    \n",
    "    error2 = np.multiply(error3.dot(theta2), gz2)\n",
    "    #error2.shape - 5000 * 26\n",
    "    \n",
    "    delta2 = error3.T.dot(a2)\n",
    "    # delta2.shape - 10 * 26\n",
    "    \n",
    "    # ignore error2[:,0]\n",
    "    delta1 = error2[:, 1:].T.dot(x)\n",
    "    # delta1.shape - 25 * 401\n",
    "    \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    reg1 = theta1 * lam / m\n",
    "    reg1[:, 0] = 0\n",
    "    reg2 = theta2 * lam / m\n",
    "    reg2[:, 0] = 0\n",
    "    \n",
    "    delta1 += reg1\n",
    "    delta2 += reg2\n",
    "    \n",
    "    delta = np.append(delta1.flatten(), delta2.flatten())\n",
    "    #print ('delta', delta.shape)\n",
    "    \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compGradReg(theta, hid_size, x, y, num_labels, lam):\n",
    "    epsilon = 0.0001\n",
    "    grad = np.zeros(theta.shape)\n",
    "    for i in range(len(theta)):\n",
    "        theta_pos = copy.copy(theta)\n",
    "        theta_neg = copy.copy(theta)\n",
    "        theta_pos[i] += epsilon\n",
    "        theta_neg[i] -= epsilon\n",
    "        \n",
    "        grad[i] = (nnCostReg(theta_pos, hid_size, x, y, num_labels, lam) - nnCostReg(theta_neg, hid_size, x, y, num_labels, lam)) /2/epsilon\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkGradReg(in_size, hid_size, n_labels, m, lam=1):\n",
    "    # prep data\n",
    "    theta1 = randInit(in_size, hid_size)\n",
    "    #print (\"theta1\", theta1.shape)\n",
    "    theta2 = randInit(hid_size, n_labels)\n",
    "    #print (\"theta2\", theta2.shape)\n",
    "    x = randInit(in_size - 1, m)\n",
    "    #print (\"x\", x.shape)\n",
    "    y = (np.random.randint(1, n_labels+1, m)).reshape(m, 1)\n",
    "    \n",
    "    t1 = theta1.flatten()\n",
    "    t2 = theta2.flatten()\n",
    "    t = np.append(t1, t2)\n",
    "    \n",
    "    gradNN = backpropReg(t, hid_size, x, y, n_labels, lam)\n",
    "    gradC = compGradReg(t, hid_size, x, y, n_labels, lam)\n",
    "    \n",
    "    diff = abs(gradNN - gradC)\n",
    "    \n",
    "    return (diff <= 1e-9).all() == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "if checkGradReg(3, 5, 3, 5) == True:\n",
    "    print ('Gradient check passed!')\n",
    "else: print ('Go check again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.319066\n",
      "         Iterations: 400\n",
      "         Function evaluations: 952\n",
      "         Gradient evaluations: 952\n"
     ]
    }
   ],
   "source": [
    "# learn the model with fmin_cg\n",
    "# initialize theta\n",
    "theta1 = randInit(400, 25)\n",
    "theta2 = randInit(25, 10)\n",
    "theta0 = np.append(theta1.flatten(), theta2.flatten())\n",
    "lam = 1\n",
    "hid_size = 25\n",
    "n_labels = 10\n",
    "x = data_x\n",
    "y = data_y\n",
    "\n",
    "myargs = (hid_size, x, y, n_labels, lam)\n",
    "\n",
    "# train the model\n",
    "train = fmin_cg(nnCostReg, theta0, args = myargs, fprime = backpropReg, maxiter = 400)\n",
    "#train = fmin_cg(nnCostReg, theta0, args = myargs, fprime = backpropReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.30460907e+00, -2.58706804e-06, -4.23571566e-06, ...,\n",
       "        1.61295836e+00, -3.24100744e-01,  1.39661960e+00])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, hid_size, x, num_labels):\n",
    "    m = x.shape[0]\n",
    "    inp_size = x.shape[1]\n",
    "    theta_cutoff = hid_size * (inp_size + 1)\n",
    "    theta1 = theta[:theta_cutoff].reshape((hid_size, inp_size + 1))\n",
    "    theta2 = theta[theta_cutoff:].reshape((num_labels, hid_size + 1))\n",
    "    \n",
    "    x = np.insert(x, 0, 1, axis = 1)\n",
    "    hidden = sigmoid(x.dot(theta1.T))\n",
    "    # a2 = hid\n",
    "    a2 = np.insert(hidden, 0, 1, axis = 1)\n",
    "    # a3 = pred\n",
    "    a3 = sigmoid(a2.dot(theta2.T))\n",
    "    pred = np.argmax(a3, axis = 1)\n",
    "    pred += 1\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, pred):\n",
    "    y = y.flatten()\n",
    "    m = len(y)\n",
    "    count = (y == pred).sum()\n",
    "    accuracy = count / m\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9942"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predict(train, 25, data_x, 10)\n",
    "accu = accuracy(data_y, pred)\n",
    "accu\n",
    "# the accuracy is 99.42% when lambda is 1\n",
    "# accu = 98.62% when lambda is 2\n",
    "# accu = 97.66% when lambda is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 400)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize hidden layer\n",
    "theta1 = train[:10025].reshape(25, 401)\n",
    "tt1 = theta1[:, 1:]\n",
    "tt1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toMatrix(data, row, col):\n",
    "    mat = np.zeros(shape = (row, col))\n",
    "    m = 0\n",
    "    for j in range(col):\n",
    "        for i in range(row):\n",
    "            mat[i, j] = data[m]\n",
    "            m += 1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test2 = toMatrix(tt1[3, :], 20, 20)\n",
    "imgplot = plt.imshow(test2, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
